{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647672d-1730-49ce-9285-d8f54074888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote Training on SSH with CUDA - Hydra Sweep\n",
    "\n",
    "This notebook lets you launch a **Hydra multirun sweep** on an SSH machine with CUDA and safely disconnect while training continues.\n",
    "\n",
    "**Sweep Configuration:**\n",
    "- `model.hidden_channels`: [32, 64, 128, 256, 512]\n",
    "- `model.conv_types`: 1-layer (GEN, GCN, GAT) and 2-layer combinations\n",
    "\n",
    "**How it works:**\n",
    "- Cell 2: Launches sweep as a background process with `nohup` (survives SSH disconnect)\n",
    "- Cell 3: Monitor recent sweep logs\n",
    "- Cell 4: Check GPU utilization\n",
    "- Cell 5: Stop sweep if needed\n",
    "- Cell 6: View sweep results summary\n",
    "\n",
    "**Workflow:**\n",
    "1. Run Cell 2 to start sweep\n",
    "2. Disconnect from SSH/close notebook - sweep continues!\n",
    "3. Reconnect later and run Cell 3 to check progress\n",
    "4. Check results in `multirun/` directory when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce32ba6-caa8-47de-ada5-2ab1cf456a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hydra sweep in background...\n",
      "Logs will be written to: logs/sweep_20251028_112301.log\n",
      "\n",
      "Command: nohup python main.py -m 'training.loss.adaptive.strategy=equal_init, equal_init_ema, ema, fixed' &> logs/sweep_20251028_112301.log &\n",
      "\n",
      "✓ Hydra sweep launched in background!\n",
      "\n",
      "Useful commands:\n",
      "  Monitor live:     tail -f logs/sweep_20251028_112301.log\n",
      "  Check status:     ps aux | grep 'python main.py'\n",
      "  Kill if needed:   pkill -f 'python main.py'\n",
      "  GPU usage:        nvidia-smi\n",
      "  Results:          ls -lh multirun/\n",
      "\n",
      "Results will be saved in: multirun/YYYY-MM-DD/HH-MM-SS/\n",
      "[2025-10-28 11:23:04,161][HYDRA] Launching 4 jobs locally\n",
      "[2025-10-28 11:23:04,162][HYDRA] \t#0 : training.loss.adaptive.strategy=equal_init\n",
      "[2025-10-28 11:23:04,257][__main__][INFO] - ==================================================\n",
      "[2025-10-28 11:23:04,257][__main__][INFO] - CONFIGURATION\n",
      "[2025-10-28 11:23:04,257][__main__][INFO] - ==================================================\n",
      "[2025-10-28 11:23:04,260][__main__][INFO] - \n",
      "dataset:\n",
      "  num_graphs: 5000\n",
      "  num_steps: 6\n",
      "  dt: 0.01\n",
      "  train_ratio: 0.8\n",
      "  batch_size: 4\n",
      "  shuffle: true\n",
      "  drop_last: false\n",
      "  wave_speed: 1.0\n",
      "  damping: 1.0\n",
      "  num_nodes: 100\n",
      "  domain_length: 1.0\n",
      "  force:\n",
      "    margin: 0.1\n",
      "    sign: -1.0\n",
      "    location: casual\n",
      "    forcing_type: middle\n",
      "  scaling:\n",
      "    enabled: false\n",
      "    method: standard\n",
      "    per_feature: true\n",
      "    epsilon: 1.0e-08\n",
      "model:\n",
      "  in_channels: 3\n",
      "  hidden_channels:\n",
      "  - 64\n",
      "  - 128\n",
      "  out_channels: 2\n",
      "  conv_types:\n",
      "  - GCN\n",
      "  - GCN\n",
      "  final_layer_type: Linear\n",
      "  activation: relu\n",
      "  dropout: 0.1\n",
      "  block: res\n",
      "  use_bn: true\n",
      "  gat_heads: 4\n",
      "  cheb_K: 3\n",
      "  residual: true\n",
      "  use_global_pooling: true\n",
      "  pooling_position: middle\n",
      "  pooling_type: attention\n",
      "  encoder_layers: 2\n",
      "  decoder_channels: null\n",
      "  graph_output_dim: null\n",
      "  use_ed_skip: true\n",
      "  ed_skip_type: concat\n",
      "training:\n",
      "  epochs: 30\n",
      "  learning_rate: 0.01\n",
      "  weight_decay: 1.0e-05\n",
      "  optimizer: adam\n",
      "  grad_clip_norm: 1.0\n",
      "  scale_lr_with_dataset: true\n",
      "  lr_baseline_size: 1000\n",
      "  loss:\n",
      "    w1_PI: 132.3\n",
      "    w2_PI: 698.1\n",
      "    use_energy: true\n",
      "    w_energy: 1000.0\n",
      "    use_rk4: false\n",
      "    w1_rk4: 132.3\n",
      "    w2_rk4: 698.1\n",
      "    use_gn_solver: false\n",
      "    adaptive:\n",
      "      enabled: true\n",
      "      strategy: equal_init\n",
      "      ema_alpha: 0.8\n",
      "      update_frequency: 1\n",
      "  log_interval: 5\n",
      "  save_best: true\n",
      "  checkpoint_path: best_model.pt\n",
      "  early_stopping:\n",
      "    enabled: true\n",
      "    patience: 50\n",
      "    min_delta: 1.0e-06\n",
      "wandb:\n",
      "  enabled: true\n",
      "  project: wave-gnn\n",
      "  entity: g-cap\n",
      "  mode: online\n",
      "  name: null\n",
      "  group: ${experiment.name}\n",
      "  tags: []\n",
      "  log_model: false\n",
      "experiment:\n",
      "  name: gcn_string_wave\n",
      "  seed: 42\n",
      "  device: cuda\n",
      "  output_dir: ./outputs\n",
      "  save_dir: ./checkpoints\n",
      "run:\n",
      "  train: true\n",
      "plot:\n",
      "  plot_dataset: false\n",
      "  load_gt: true\n",
      "  look_up_every: false\n",
      "\n",
      "[2025-10-28 11:23:04,261][__main__][INFO] - Random seed set to 42\n",
      "[2025-10-28 11:23:04,261][__main__][INFO] - Output directory: outputs\n",
      "[2025-10-28 11:23:04,261][__main__][INFO] - Checkpoint directory: checkpoints\n",
      "[2025-10-28 11:23:04,265][__main__][INFO] - Configuration saved to outputs/config_20251028_112304.yaml\n",
      "[2025-10-28 11:23:04,265][__main__][INFO] - ==================================================\n",
      "[2025-10-28 11:23:04,265][__main__][INFO] - CREATING DATASET\n",
      "[2025-10-28 11:23:04,265][__main__][INFO] - ==================================================\n",
      "[2025-10-28 11:23:21,611][__main__][INFO] - Dataset created: 5000 graphs\n",
      "[2025-10-28 11:23:21,611][__main__][INFO] -   - Number of graphs: 5000\n",
      "[2025-10-28 11:23:21,611][__main__][INFO] -   - Timesteps per graph: 6\n",
      "[2025-10-28 11:23:21,611][__main__][INFO] -   - Time step (dt): 0.01\n",
      "[2025-10-28 11:23:21,611][__main__][INFO] -   - Batch size: 4\n",
      "[2025-10-28 11:23:21,611][__main__][INFO] -   - Training samples: 4000\n",
      "[2025-10-28 11:23:21,611][__main__][INFO] -   - Validation samples: 1000\n",
      "[2025-10-28 11:23:21,611][__main__][INFO] - \n",
      "==================================================\n",
      "[2025-10-28 11:23:21,611][__main__][INFO] - TRAINING MODEL\n",
      "[2025-10-28 11:23:21,611][__main__][INFO] - ==================================================\n",
      "[2025-10-28 11:23:21,611][train][INFO] - Using device: cuda\n",
      "[2025-10-28 11:23:21,748][train][INFO] - Model architecture: DeepGCN(\n",
      "  (input_proj): Linear(in_features=3, out_features=64, bias=True)\n",
      "  (encoder_layers): ModuleList(\n",
      "    (0): DeepGCNLayer(block=res)\n",
      "    (1): DeepGCNLayer(block=plain)\n",
      "  )\n",
      "  (attention_weights): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (decoder_layers): ModuleList(\n",
      "    (0-1): 2 x DeepGCNLayer(block=plain)\n",
      "  )\n",
      "  (final_layer): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "[2025-10-28 11:23:21,748][train][INFO] - ✓ Residual mode enabled: Model predicts changes (Δu, Δv)\n",
      "[2025-10-28 11:23:21,748][train][INFO] - Learning rate scaling enabled:\n",
      "[2025-10-28 11:23:21,749][train][INFO] -   - Base LR: 0.010000\n",
      "[2025-10-28 11:23:21,749][train][INFO] -   - Dataset size: 4000\n",
      "[2025-10-28 11:23:21,749][train][INFO] -   - Baseline size: 1000\n",
      "[2025-10-28 11:23:21,749][train][INFO] -   - Scale factor: 2.0000\n",
      "[2025-10-28 11:23:21,749][train][INFO] -   - Scaled LR: 0.020000\n",
      "[2025-10-28 11:23:21,749][adaptive_weights][INFO] - Adaptive loss weights initialized with strategy: equal_init\n",
      "[2025-10-28 11:23:21,749][adaptive_weights][INFO] - Initial weights: {'PI_loss1': 132.3, 'PI_loss2': 698.1, 'Energy_loss': 1000.0}\n",
      "[2025-10-28 11:23:21,749][train][INFO] - ==================================================\n",
      "[2025-10-28 11:23:21,749][train][INFO] - Adaptive loss weighting enabled\n",
      "[2025-10-28 11:23:21,749][train][INFO] - Strategy: equal_init\n",
      "[2025-10-28 11:23:21,749][train][INFO] - Initial weights: {'PI_loss1': 132.3, 'PI_loss2': 698.1, 'Energy_loss': 1000.0}\n",
      "[2025-10-28 11:23:21,749][train][INFO] - ==================================================\n",
      "[2025-10-28 11:23:21,749][train][INFO] - Starting training for 30 epochs...\n",
      "[2025-10-28 11:23:49,196][adaptive_weights][INFO] - Equalized weights at epoch 1:\n",
      "[2025-10-28 11:23:49,196][adaptive_weights][INFO] -   PI_loss1: loss=4.924e-06, weight=6.761e+04, weighted=3.329e-01\n",
      "[2025-10-28 11:23:49,196][adaptive_weights][INFO] -   PI_loss2: loss=3.581e-05, weight=9.314e+03, weighted=3.335e-01\n",
      "[2025-10-28 11:23:49,196][adaptive_weights][INFO] -   Energy_loss: loss=4.206e+00, weight=7.932e-02, weighted=3.336e-01\n",
      "[2025-10-28 11:23:53,015][train][INFO] - Epoch 001 | Train 7.842e+00 | PI1 4.924e-06 | PI2 3.581e-05 | Energy 4.206e+00 | Val 1.278e-03 | PI1 2.426e-08 | PI2 1.826e-06\n"
     ]
    }
   ],
   "source": [
    "# This is for sweep\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create logs directory if it doesn't exist\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "# Generate unique log filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = f\"logs/sweep_{timestamp}.log\"\n",
    "\n",
    "print(f\"Starting Hydra sweep in background...\")\n",
    "print(f\"Logs will be written to: {log_file}\")\n",
    "\n",
    "# Hydra multirun command with sweep parameters\n",
    "# -m flag enables multirun mode\n",
    "# Sweep over hidden_channels and conv_types\n",
    "cmd = (\n",
    "    f\"nohup python main.py -m \"\n",
    "    f\"'training.loss.adaptive.strategy=equal_init, equal_init_ema, ema, fixed' \"\n",
    "    f\"&> {log_file} &\"\n",
    ")\n",
    "\n",
    "print(f\"\\nCommand: {cmd}\")\n",
    "os.system(cmd)\n",
    "\n",
    "print(\"\\n✓ Hydra sweep launched in background!\")\n",
    "print(f\"\\nUseful commands:\")\n",
    "print(f\"  Monitor live:     tail -f {log_file}\")\n",
    "print(f\"  Check status:     ps aux | grep 'python main.py'\")\n",
    "print(f\"  Kill if needed:   pkill -f 'python main.py'\")\n",
    "print(f\"  GPU usage:        nvidia-smi\")\n",
    "print(f\"  Results:          ls -lh multirun/\")\n",
    "print(f\"\\nResults will be saved in: multirun/YYYY-MM-DD/HH-MM-SS/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "284fec57-66c8-4c11-9e38-7d8b48d50f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring: logs/sweep_20251028_103052.log\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Total lines in log: 0\n",
      "[2025-10-28 10:30:56,589][HYDRA] Launching 30 jobs locally\n",
      "[2025-10-28 10:30:56,589][HYDRA] \t#0 : model.hidden_channels=32 model.conv_types=GEN\n",
      "[2025-10-28 10:30:56,680][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:30:56,680][__main__][INFO] - CONFIGURATION\n",
      "[2025-10-28 10:30:56,680][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:30:56,684][__main__][INFO] - \n",
      "dataset:\n",
      "  num_graphs: 100\n",
      "  num_steps: 6\n",
      "  dt: 0.1\n",
      "  train_ratio: 0.8\n",
      "  batch_size: 4\n",
      "  shuffle: true\n",
      "  drop_last: false\n",
      "  wave_speed: 1.0\n",
      "  damping: 1.0\n",
      "  num_nodes: 100\n",
      "  domain_length: 1.0\n",
      "  force:\n",
      "    margin: 0.1\n",
      "    sign: -1.0\n",
      "    location: casual\n",
      "    forcing_type: middle\n",
      "  scaling:\n",
      "    enabled: false\n",
      "    method: standard\n",
      "    per_feature: true\n",
      "    epsilon: 1.0e-08\n",
      "model:\n",
      "  in_channels: 3\n",
      "  hidden_channels: 32\n",
      "  out_channels: 2\n",
      "  conv_types: GEN\n",
      "  final_layer_type: Linear\n",
      "  activation: relu\n",
      "  dropout: 0.2\n",
      "  block: res\n",
      "  use_bn: true\n",
      "  gat_heads: 4\n",
      "  cheb_K: 3\n",
      "  residual: true\n",
      "  use_global_pooling: true\n",
      "  pooling_position: middle\n",
      "  pooling_type: attention\n",
      "  encoder_layers: 4\n",
      "  decoder_channels: null\n",
      "  graph_output_dim: null\n",
      "  use_ed_skip: true\n",
      "  ed_skip_type: concat\n",
      "training:\n",
      "  epochs: 10\n",
      "  learning_rate: 0.01\n",
      "  weight_decay: 1.0e-05\n",
      "  optimizer: adam\n",
      "  grad_clip_norm: 1.0\n",
      "  scale_lr_with_dataset: true\n",
      "  lr_baseline_size: 1000\n",
      "  loss:\n",
      "    w1_PI: 132.3\n",
      "    w2_PI: 698.1\n",
      "    use_energy: true\n",
      "    w_energy: 1000.0\n",
      "    use_rk4: false\n",
      "    w1_rk4: 132.3\n",
      "    w2_rk4: 698.1\n",
      "    use_gn_solver: false\n",
      "    adaptive:\n",
      "      enabled: true\n",
      "      strategy: fixed\n",
      "      ema_alpha: 0.8\n",
      "      update_frequency: 1\n",
      "  log_interval: 5\n",
      "  save_best: true\n",
      "  checkpoint_path: best_model.pt\n",
      "  early_stopping:\n",
      "    enabled: true\n",
      "    patience: 50\n",
      "    min_delta: 1.0e-06\n",
      "wandb:\n",
      "  enabled: true\n",
      "  project: wave-gnn\n",
      "  entity: g-cap\n",
      "  mode: online\n",
      "  name: null\n",
      "  group: ${experiment.name}\n",
      "  tags: []\n",
      "  log_model: false\n",
      "experiment:\n",
      "  name: gcn_string_wave\n",
      "  seed: 42\n",
      "  device: cuda\n",
      "  output_dir: ./outputs\n",
      "  save_dir: ./checkpoints\n",
      "run:\n",
      "  train: true\n",
      "plot:\n",
      "  plot_dataset: false\n",
      "  load_gt: true\n",
      "  look_up_every: false\n",
      "\n",
      "[2025-10-28 10:30:56,685][__main__][INFO] - Random seed set to 42\n",
      "[2025-10-28 10:30:56,685][__main__][INFO] - Output directory: outputs\n",
      "[2025-10-28 10:30:56,685][__main__][INFO] - Checkpoint directory: checkpoints\n",
      "[2025-10-28 10:30:56,689][__main__][INFO] - Configuration saved to outputs/config_20251028_103056.yaml\n",
      "[2025-10-28 10:30:56,689][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:30:56,689][__main__][INFO] - CREATING DATASET\n",
      "[2025-10-28 10:30:56,689][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:30:57,046][__main__][INFO] - Dataset created: 100 graphs\n",
      "[2025-10-28 10:30:57,046][__main__][INFO] -   - Number of graphs: 100\n",
      "[2025-10-28 10:30:57,046][__main__][INFO] -   - Timesteps per graph: 6\n",
      "[2025-10-28 10:30:57,046][__main__][INFO] -   - Time step (dt): 0.1\n",
      "[2025-10-28 10:30:57,046][__main__][INFO] -   - Batch size: 4\n",
      "[2025-10-28 10:30:57,047][__main__][INFO] -   - Training samples: 80\n",
      "[2025-10-28 10:30:57,047][__main__][INFO] -   - Validation samples: 20\n",
      "[2025-10-28 10:30:57,047][__main__][INFO] - \n",
      "==================================================\n",
      "[2025-10-28 10:30:57,047][__main__][INFO] - TRAINING MODEL\n",
      "[2025-10-28 10:30:57,047][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:30:57,047][train][INFO] - Using device: cuda\n",
      "[2025-10-28 10:30:57,168][train][INFO] - Model architecture: DeepGCN(\n",
      "  (input_proj): Linear(in_features=3, out_features=32, bias=True)\n",
      "  (encoder_layers): ModuleList(\n",
      "    (0): DeepGCNLayer(block=res)\n",
      "  )\n",
      "  (attention_weights): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (decoder_layers): ModuleList(\n",
      "    (0): DeepGCNLayer(block=plain)\n",
      "  )\n",
      "  (final_layer): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "[2025-10-28 10:30:57,168][train][INFO] - ✓ Residual mode enabled: Model predicts changes (Δu, Δv)\n",
      "[2025-10-28 10:30:57,168][train][INFO] - Learning rate scaling enabled:\n",
      "[2025-10-28 10:30:57,168][train][INFO] -   - Base LR: 0.010000\n",
      "[2025-10-28 10:30:57,168][train][INFO] -   - Dataset size: 80\n",
      "[2025-10-28 10:30:57,168][train][INFO] -   - Baseline size: 1000\n",
      "[2025-10-28 10:30:57,168][train][INFO] -   - Scale factor: 0.2828\n",
      "[2025-10-28 10:30:57,168][train][INFO] -   - Scaled LR: 0.002828\n",
      "[2025-10-28 10:30:57,169][adaptive_weights][INFO] - Adaptive loss weights initialized with strategy: fixed\n",
      "[2025-10-28 10:30:57,169][adaptive_weights][INFO] - Initial weights: {'PI_loss1': 132.3, 'PI_loss2': 698.1}\n",
      "[2025-10-28 10:30:57,169][train][INFO] - ==================================================\n",
      "[2025-10-28 10:30:57,169][train][INFO] - Adaptive loss weighting enabled\n",
      "[2025-10-28 10:30:57,169][train][INFO] - Strategy: fixed\n",
      "[2025-10-28 10:30:57,169][train][INFO] - Initial weights: {'PI_loss1': 132.3, 'PI_loss2': 698.1}\n",
      "[2025-10-28 10:30:57,169][train][INFO] - ==================================================\n",
      "[2025-10-28 10:30:57,169][train][INFO] - Starting training for 10 epochs...\n",
      "[2025-10-28 10:30:58,233][train][INFO] - Epoch 001 | Train 2.188e+01 | PI1 1.305e-03 | PI2 1.855e-03 | Energy 1.528e+01 | Val 1.073e-01 | PI1 1.507e-04 | PI2 1.252e-04\n",
      "[2025-10-28 10:31:00,470][train][INFO] - Epoch 005 | Train 3.209e+00 | PI1 1.496e-04 | PI2 4.046e-04 | Energy 2.028e+00 | Val 9.482e-02 | PI1 1.761e-04 | PI2 1.025e-04\n",
      "[2025-10-28 10:31:03,300][train][INFO] - Epoch 010 | Train 1.852e-01 | PI1 7.625e-05 | PI2 2.509e-04 | Energy 0.000e+00 | Val 1.817e-01 | PI1 9.489e-06 | PI2 2.584e-04\n",
      "        Weights: PI1=1.32e+02, PI2=6.98e+02\n",
      "[2025-10-28 10:31:03,300][train][INFO] - Training finished. Best validation PDE MSE: 9.481646e-02\n",
      "[2025-10-28 10:31:03,300][train][INFO] - Total training time: 0:00:06.130966\n",
      "[2025-10-28 10:31:03,301][__main__][INFO] - Training completed. Best model saved to checkpoints/best_model_20251028_103056.pt\n",
      "[2025-10-28 10:31:03,301][__main__][INFO] - Best validation PDE MSE: 9.481646e-02\n",
      "[2025-10-28 10:31:03,301][__main__][INFO] - \n",
      "==================================================\n",
      "[2025-10-28 10:31:03,301][__main__][INFO] - TESTING MODEL\n",
      "[2025-10-28 10:31:03,301][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:31:03,301][test_gcn][INFO] - Loading model from checkpoints/best_model_20251028_103056.pt\n",
      "[2025-10-28 10:31:03,315][test_gcn][INFO] - ✓ Model in residual mode: Predicts changes (Δu, Δv)\n",
      "[2025-10-28 10:31:03,319][test_gcn][INFO] - Running simulation...\n",
      "[2025-10-28 10:31:03,546][test_gcn][INFO] - Simulation complete: 101 time steps in 0:00:00.227421\n",
      "[2025-10-28 10:31:03,548][test_gcn][INFO] - Each step = one GNN forward pass\n",
      "[2025-10-28 10:31:03,548][test_gcn][INFO] - MATLAB data saved to outputs/matlab/data_gcn_20251028_103056.mat\n",
      "Saved static 2D feature map with 6 features (2x3 layout) as 'outputs/figures/gcn_string_pred_20251028_103056_0.png'\n",
      "[2025-10-28 10:31:04,453][test_gcn][INFO] - Plot saved to outputs/figures/gcn_string_pred_20251028_103056_0.png\n",
      "[2025-10-28 10:31:04,454][__main__][INFO] - Testing completed.\n",
      "[2025-10-28 10:31:04,454][__main__][INFO] - Results saved to checkpoints\n",
      "[2025-10-28 10:31:04,465][__main__][INFO] - \n",
      "Experiment summary saved to outputs/summary_20251028_103056.yaml\n",
      "[2025-10-28 10:31:04,465][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:31:04,465][__main__][INFO] - EXPERIMENT COMPLETED SUCCESSFULLY\n",
      "[2025-10-28 10:31:04,465][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:31:04,466][HYDRA] \t#1 : model.hidden_channels=32 model.conv_types=GCN\n",
      "[2025-10-28 10:31:04,566][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:31:04,566][__main__][INFO] - CONFIGURATION\n",
      "[2025-10-28 10:31:04,566][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:31:04,569][__main__][INFO] - \n",
      "dataset:\n",
      "  num_graphs: 100\n",
      "  num_steps: 6\n",
      "  dt: 0.1\n",
      "  train_ratio: 0.8\n",
      "  batch_size: 4\n",
      "  shuffle: true\n",
      "  drop_last: false\n",
      "  wave_speed: 1.0\n",
      "  damping: 1.0\n",
      "  num_nodes: 100\n",
      "  domain_length: 1.0\n",
      "  force:\n",
      "    margin: 0.1\n",
      "    sign: -1.0\n",
      "    location: casual\n",
      "    forcing_type: middle\n",
      "  scaling:\n",
      "    enabled: false\n",
      "    method: standard\n",
      "    per_feature: true\n",
      "    epsilon: 1.0e-08\n",
      "model:\n",
      "  in_channels: 3\n",
      "  hidden_channels: 32\n",
      "  out_channels: 2\n",
      "  conv_types: GCN\n",
      "  final_layer_type: Linear\n",
      "  activation: relu\n",
      "  dropout: 0.2\n",
      "  block: res\n",
      "  use_bn: true\n",
      "  gat_heads: 4\n",
      "  cheb_K: 3\n",
      "  residual: true\n",
      "  use_global_pooling: true\n",
      "  pooling_position: middle\n",
      "  pooling_type: attention\n",
      "  encoder_layers: 4\n",
      "  decoder_channels: null\n",
      "  graph_output_dim: null\n",
      "  use_ed_skip: true\n",
      "  ed_skip_type: concat\n",
      "training:\n",
      "  epochs: 10\n",
      "  learning_rate: 0.01\n",
      "  weight_decay: 1.0e-05\n",
      "  optimizer: adam\n",
      "  grad_clip_norm: 1.0\n",
      "  scale_lr_with_dataset: true\n",
      "  lr_baseline_size: 1000\n",
      "  loss:\n",
      "    w1_PI: 132.3\n",
      "    w2_PI: 698.1\n",
      "    use_energy: true\n",
      "    w_energy: 1000.0\n",
      "    use_rk4: false\n",
      "    w1_rk4: 132.3\n",
      "    w2_rk4: 698.1\n",
      "    use_gn_solver: false\n",
      "    adaptive:\n",
      "      enabled: true\n",
      "      strategy: fixed\n",
      "      ema_alpha: 0.8\n",
      "      update_frequency: 1\n",
      "  log_interval: 5\n",
      "  save_best: true\n",
      "  checkpoint_path: best_model.pt\n",
      "  early_stopping:\n",
      "    enabled: true\n",
      "    patience: 50\n",
      "    min_delta: 1.0e-06\n",
      "wandb:\n",
      "  enabled: true\n",
      "  project: wave-gnn\n",
      "  entity: g-cap\n",
      "  mode: online\n",
      "  name: null\n",
      "  group: ${experiment.name}\n",
      "  tags: []\n",
      "  log_model: false\n",
      "experiment:\n",
      "  name: gcn_string_wave\n",
      "  seed: 42\n",
      "  device: cuda\n",
      "  output_dir: ./outputs\n",
      "  save_dir: ./checkpoints\n",
      "run:\n",
      "  train: true\n",
      "plot:\n",
      "  plot_dataset: false\n",
      "  load_gt: true\n",
      "  look_up_every: false\n",
      "\n",
      "[2025-10-28 10:31:04,570][__main__][INFO] - Random seed set to 42\n",
      "[2025-10-28 10:31:04,570][__main__][INFO] - Output directory: outputs\n",
      "[2025-10-28 10:31:04,570][__main__][INFO] - Checkpoint directory: checkpoints\n",
      "[2025-10-28 10:31:04,573][__main__][INFO] - Configuration saved to outputs/config_20251028_103104.yaml\n",
      "[2025-10-28 10:31:04,573][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:31:04,573][__main__][INFO] - CREATING DATASET\n",
      "[2025-10-28 10:31:04,573][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:31:04,932][__main__][INFO] - Dataset created: 100 graphs\n",
      "[2025-10-28 10:31:04,932][__main__][INFO] -   - Number of graphs: 100\n",
      "[2025-10-28 10:31:04,932][__main__][INFO] -   - Timesteps per graph: 6\n",
      "[2025-10-28 10:31:04,932][__main__][INFO] -   - Time step (dt): 0.1\n",
      "[2025-10-28 10:31:04,932][__main__][INFO] -   - Batch size: 4\n",
      "[2025-10-28 10:31:04,932][__main__][INFO] -   - Training samples: 80\n",
      "[2025-10-28 10:31:04,932][__main__][INFO] -   - Validation samples: 20\n",
      "[2025-10-28 10:31:04,932][__main__][INFO] - \n",
      "==================================================\n",
      "[2025-10-28 10:31:04,932][__main__][INFO] - TRAINING MODEL\n",
      "[2025-10-28 10:31:04,932][__main__][INFO] - ==================================================\n",
      "[2025-10-28 10:31:04,932][train][INFO] - Using device: cuda\n",
      "[2025-10-28 10:31:04,959][train][INFO] - Model architecture: DeepGCN(\n",
      "  (input_proj): Linear(in_features=3, out_features=32, bias=True)\n",
      "  (encoder_layers): ModuleList(\n",
      "    (0): DeepGCNLayer(block=res)\n",
      "  )\n",
      "  (attention_weights): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (decoder_layers): ModuleList(\n",
      "    (0): DeepGCNLayer(block=plain)\n",
      "  )\n",
      "  (final_layer): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "[2025-10-28 10:31:04,959][train][INFO] - ✓ Residual mode enabled: Model predicts changes (Δu, Δv)\n",
      "[2025-10-28 10:31:04,959][train][INFO] - Learning rate scaling enabled:\n",
      "[2025-10-28 10:31:04,959][train][INFO] -   - Base LR: 0.010000\n",
      "[2025-10-28 10:31:04,959][train][INFO] -   - Dataset size: 80\n",
      "[2025-10-28 10:31:04,959][train][INFO] -   - Baseline size: 1000\n",
      "[2025-10-28 10:31:04,959][train][INFO] -   - Scale factor: 0.2828\n",
      "[2025-10-28 10:31:04,959][train][INFO] -   - Scaled LR: 0.002828\n",
      "[2025-10-28 10:31:04,960][adaptive_weights][INFO] - Adaptive loss weights initialized with strategy: fixed\n",
      "[2025-10-28 10:31:04,960][adaptive_weights][INFO] - Initial weights: {'PI_loss1': 132.3, 'PI_loss2': 698.1}\n",
      "[2025-10-28 10:31:04,960][train][INFO] - ==================================================\n",
      "[2025-10-28 10:31:04,960][train][INFO] - Adaptive loss weighting enabled\n",
      "[2025-10-28 10:31:04,960][train][INFO] - Strategy: fixed\n",
      "[2025-10-28 10:31:04,960][train][INFO] - Initial weights: {'PI_loss1': 132.3, 'PI_loss2': 698.1}\n",
      "[2025-10-28 10:31:04,960][train][INFO] - ==================================================\n",
      "[2025-10-28 10:31:04,960][train][INFO] - Starting training for 10 epochs...\n",
      "[2025-10-28 10:31:05,493][train][INFO] - Epoch 001 | Train 1.582e+01 | PI1 1.363e-03 | PI2 5.266e-03 | Energy 1.928e+01 | Val 9.718e+00 | PI1 7.593e-04 | PI2 1.378e-02\n",
      "[2025-10-28 10:31:07,588][train][INFO] - Epoch 005 | Train 7.382e-01 | PI1 1.698e-04 | PI2 4.427e-04 | Energy 8.572e-02 | Val 1.376e-01 | PI1 3.571e-04 | PI2 1.294e-04\n"
     ]
    }
   ],
   "source": [
    "# Monitor the most recent sweep log\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# Find most recent log file\n",
    "log_files = sorted(glob.glob('logs/sweep_*.log'))\n",
    "if log_files:\n",
    "    latest_log = log_files[-1]\n",
    "    print(f\"Monitoring: {latest_log}\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Display last 50 lines to see multiple runs\n",
    "    with open(latest_log, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[-50:]:\n",
    "            print(line.rstrip())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Total lines in log: {len(lines)}\")\n",
    "else:\n",
    "    print(\"No sweep logs found yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84af0fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 27 19:41:42 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| 30%   51C    P2             123W / 370W |    372MiB / 24576MiB |     15%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check GPU utilization\n",
    "import subprocess\n",
    "\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e45792b-9baf-4662-97c8-64a9bdfd427a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping all training processes...\n",
      "✓ Training processes stopped\n",
      "✓ All training processes terminated\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "print(\"Stopping all training processes...\")\n",
    "subprocess.run(['pkill', '-f', 'python main.py'])\n",
    "print(\"✓ Training processes stopped\")\n",
    "\n",
    "# Verify\n",
    "result = subprocess.run(['pgrep', '-f', 'python main.py'], capture_output=True)\n",
    "if result.stdout:\n",
    "    print(\"⚠ Some processes still running, try again or use: kill -9 <PID>\")\n",
    "else:\n",
    "    print(\"✓ All training processes terminated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb608bb1-d30f-4e1a-9195-7397ac6d0d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
