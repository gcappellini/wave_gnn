{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647672d-1730-49ce-9285-d8f54074888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remote Training on SSH with CUDA\n",
    "\n",
    "This notebook lets you launch training on an SSH machine with CUDA and safely disconnect while training continues.\n",
    "\n",
    "**How it works:**\n",
    "- Cell 2: Launches training as a background process with `nohup` (survives SSH disconnect)\n",
    "- Cell 3: Monitor recent training logs\n",
    "- Cell 4: Check GPU utilization\n",
    "- Cell 5: Stop training if needed\n",
    "\n",
    "**Workflow:**\n",
    "1. Run Cell 2 to start training\n",
    "2. Disconnect from SSH/close notebook - training continues!\n",
    "3. Reconnect later and run Cell 3 to check progress\n",
    "4. Check outputs in `checkpoints/` and `outputs/` directories when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce32ba6-caa8-47de-ada5-2ab1cf456a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-22 13:43:21,761][__main__][INFO] - ==================================================\n",
      "[2025-10-22 13:43:21,761][__main__][INFO] - CONFIGURATION\n",
      "[2025-10-22 13:43:21,761][__main__][INFO] - ==================================================\n",
      "[2025-10-22 13:43:21,764][__main__][INFO] - \n",
      "dataset:\n",
      "  num_graphs: 10000\n",
      "  num_steps: 6\n",
      "  dt: 0.01\n",
      "  train_ratio: 0.8\n",
      "  batch_size: 32\n",
      "  shuffle: true\n",
      "  drop_last: false\n",
      "  wave_speed: 1.0\n",
      "  damping: 1.0\n",
      "  num_nodes: 100\n",
      "  domain_length: 1.0\n",
      "  force:\n",
      "    margin: 0.1\n",
      "    sign: -1.0\n",
      "    location: casual\n",
      "    forcing_type: middle\n",
      "  scaling:\n",
      "    enabled: true\n",
      "    method: standard\n",
      "    per_feature: true\n",
      "    epsilon: 1.0e-08\n",
      "model:\n",
      "  in_channels: 3\n",
      "  hidden_channels:\n",
      "  - 64\n",
      "  - 128\n",
      "  - 256\n",
      "  - 512\n",
      "  out_channels: 2\n",
      "  conv_types:\n",
      "  - GEN\n",
      "  - GEN\n",
      "  - GEN\n",
      "  - GEN\n",
      "  final_layer_type: Linear\n",
      "  activation: relu\n",
      "  dropout: 0.1\n",
      "  block: plain\n",
      "  use_bn: true\n",
      "  gat_heads: 4\n",
      "  cheb_K: 3\n",
      "  residual: false\n",
      "  use_global_pooling: true\n",
      "  pooling_position: middle\n",
      "  pooling_type: mean\n",
      "  encoder_layers: 4\n",
      "  decoder_channels: null\n",
      "  graph_output_dim: null\n",
      "training:\n",
      "  epochs: 30\n",
      "  learning_rate: 0.005\n",
      "  weight_decay: 1.0e-05\n",
      "  optimizer: adam\n",
      "  loss:\n",
      "    w1_PI: 1.0\n",
      "    w2_PI: 1.0\n",
      "    use_rk4: true\n",
      "    w1_rk4: 1.0\n",
      "    w2_rk4: 1.0\n",
      "    use_gn_solver: false\n",
      "    adaptive:\n",
      "      enabled: true\n",
      "      strategy: equal_init_ema\n",
      "      ema_alpha: 0.8\n",
      "      update_frequency: 1\n",
      "  log_interval: 5\n",
      "  save_best: true\n",
      "  checkpoint_path: best_model.pt\n",
      "  early_stopping:\n",
      "    enabled: true\n",
      "    patience: 10\n",
      "    min_delta: 1.0e-06\n",
      "experiment:\n",
      "  name: gcn_string_wave\n",
      "  seed: 42\n",
      "  device: cuda\n",
      "  output_dir: ./outputs\n",
      "  save_dir: ./checkpoints\n",
      "run:\n",
      "  train: true\n",
      "  plot_dataset: true\n",
      "\n",
      "[2025-10-22 13:43:21,765][__main__][INFO] - Random seed set to 42\n",
      "[2025-10-22 13:43:21,766][__main__][INFO] - Output directory: outputs\n",
      "[2025-10-22 13:43:21,766][__main__][INFO] - Checkpoint directory: checkpoints\n",
      "[2025-10-22 13:43:21,769][__main__][INFO] - Configuration saved to outputs/config.yaml\n",
      "[2025-10-22 13:43:21,769][__main__][INFO] - ==================================================\n",
      "[2025-10-22 13:43:21,769][__main__][INFO] - CREATING DATASET\n",
      "[2025-10-22 13:43:21,769][__main__][INFO] - ==================================================\n",
      "[2025-10-22 13:43:56,134][__main__][INFO] - Dataset created: 10000 graphs\n",
      "[2025-10-22 13:43:56,134][__main__][INFO] -   - Number of graphs: 10000\n",
      "[2025-10-22 13:43:56,134][__main__][INFO] -   - Timesteps per graph: 6\n",
      "[2025-10-22 13:43:56,134][__main__][INFO] -   - Time step (dt): 0.01\n",
      "[2025-10-22 13:43:56,134][__main__][INFO] -   - Batch size: 32\n",
      "Saved static 2D feature map with 3 features (1x3 layout) as 'outputs/figures/training_dataset.png'\n",
      "[2025-10-22 13:43:57,281][__main__][INFO] - Training dataset visualization saved to outputs/figures/training_dataset.png\n",
      "[2025-10-22 13:43:57,281][__main__][INFO] -   - Training samples: 8000\n",
      "[2025-10-22 13:43:57,281][__main__][INFO] -   - Validation samples: 2000\n",
      "[2025-10-22 13:43:57,281][__main__][INFO] - \n",
      "==================================================\n",
      "[2025-10-22 13:43:57,281][__main__][INFO] - TRAINING MODEL\n",
      "[2025-10-22 13:43:57,281][__main__][INFO] - ==================================================\n",
      "[2025-10-22 13:43:57,281][train][INFO] - Using device: cuda\n",
      "[2025-10-22 13:43:57,282][train][INFO] - ==================================================\n",
      "[2025-10-22 13:43:57,282][train][INFO] - Setting up data scaling...\n",
      "[2025-10-22 13:43:57,282][scaler][INFO] - Computing scaling statistics from training data...\n",
      "[2025-10-22 13:43:59,708][scaler][INFO] - Input scaling: mean=[-4.9493406e-06  2.2819318e-04 -1.5763374e-01], std=[0.00132952 0.01541815 0.47140816]\n",
      "[2025-10-22 13:43:59,709][scaler][INFO] - Output scaling: mean=[-4.9493065e-06  2.2819302e-04], std=[0.00133028 0.01542517]\n",
      "[2025-10-22 13:43:59,709][scaler][INFO] - ✓ Scaling statistics computed successfully\n",
      "[2025-10-22 13:43:59,709][scaler][INFO] - Scaler saved to checkpoints/scaler.pkl\n",
      "[2025-10-22 13:43:59,709][train][INFO] - Scaler saved to checkpoints/scaler.pkl\n",
      "[2025-10-22 13:43:59,709][train][INFO] - ==================================================\n",
      "[2025-10-22 13:43:59,844][train][INFO] - Model architecture: DeepGCN(\n",
      "  (input_proj): Linear(in_features=3, out_features=64, bias=True)\n",
      "  (encoder_layers): ModuleList(\n",
      "    (0-3): 4 x DeepGCNLayer(block=plain)\n",
      "  )\n",
      "  (decoder_layers): ModuleList(\n",
      "    (0-3): 4 x DeepGCNLayer(block=plain)\n",
      "  )\n",
      "  (final_layer): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "[2025-10-22 13:43:59,844][train][INFO] - ✓ Absolute mode: Model predicts absolute values (u, v)\n",
      "[2025-10-22 13:43:59,844][adaptive_weights][INFO] - Adaptive loss weights initialized with strategy: equal_init_ema\n",
      "[2025-10-22 13:43:59,844][adaptive_weights][INFO] - Initial weights: {'PI_loss1': 1.0, 'PI_loss2': 1.0, 'RK4_loss1': 1.0, 'RK4_loss2': 1.0}\n",
      "[2025-10-22 13:43:59,844][train][INFO] - ==================================================\n",
      "[2025-10-22 13:43:59,844][train][INFO] - Adaptive loss weighting enabled\n",
      "[2025-10-22 13:43:59,844][train][INFO] - Strategy: equal_init_ema\n",
      "[2025-10-22 13:43:59,845][train][INFO] - Initial weights: {'PI_loss1': 1.0, 'PI_loss2': 1.0, 'RK4_loss1': 1.0, 'RK4_loss2': 1.0}\n",
      "[2025-10-22 13:43:59,845][train][INFO] - ==================================================\n",
      "[2025-10-22 13:43:59,845][train][INFO] - Starting training for 30 epochs...\n",
      "[2025-10-22 13:45:54,463][adaptive_weights][INFO] - Equalized weights at epoch 1:\n",
      "[2025-10-22 13:45:54,463][adaptive_weights][INFO] -   PI_loss1: loss=1.033e+00, weight=1.107e+00, weighted=1.144e+00\n",
      "[2025-10-22 13:45:54,463][adaptive_weights][INFO] -   PI_loss2: loss=1.272e+00, weight=8.990e-01, weighted=1.144e+00\n",
      "[2025-10-22 13:45:54,463][adaptive_weights][INFO] -   RK4_loss1: loss=1.030e+00, weight=1.111e+00, weighted=1.144e+00\n",
      "[2025-10-22 13:45:54,463][adaptive_weights][INFO] -   RK4_loss2: loss=1.296e+00, weight=8.827e-01, weighted=1.144e+00\n",
      "[2025-10-22 13:46:07,113][train][INFO] - Epoch 001 | Train 4.631e+00 | PI1 1.033e+00 | PI2 1.272e+00 | RK4_1 2.010e-03 | RK4_2 3.727e-03 | Val 3.394e+11 | PI1 4.851e+08 | PI2 3.389e+11\n",
      "[2025-10-22 13:54:24,125][adaptive_weights][INFO] - Updated weights at epoch 5 (EMA strategy):\n",
      "[2025-10-22 13:54:24,125][adaptive_weights][INFO] -   PI_loss1: ema=1.023e+00, weight=1.108e+00\n",
      "[2025-10-22 13:54:24,125][adaptive_weights][INFO] -   PI_loss2: ema=1.264e+00, weight=8.984e-01\n",
      "[2025-10-22 13:54:24,125][adaptive_weights][INFO] -   RK4_loss1: ema=1.019e+00, weight=1.111e+00\n",
      "[2025-10-22 13:54:24,125][adaptive_weights][INFO] -   RK4_loss2: ema=1.287e+00, weight=8.821e-01\n",
      "[2025-10-22 13:54:36,416][train][INFO] - Epoch 005 | Train 4.533e+00 | PI1 1.022e+00 | PI2 1.263e+00 | RK4_1 4.072e-03 | RK4_2 8.974e-03 | Val 2.671e-04 | PI1 1.781e-06 | PI2 2.653e-04\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create logs directory if it doesn't exist\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "# Generate unique log filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = f\"logs/training_{timestamp}.log\"\n",
    "\n",
    "print(f\"Starting training in background...\")\n",
    "print(f\"Logs will be written to: {log_file}\")\n",
    "print(f\"To monitor progress: tail -f {log_file}\")\n",
    "print(f\"To check if still running: ps aux | grep 'python main.py'\")\n",
    "\n",
    "# Launch training as detached background process\n",
    "# nohup ensures it continues after SSH disconnect\n",
    "# &> redirects both stdout and stderr to log file\n",
    "# & runs in background\n",
    "# The process will continue even if you close this notebook or disconnect SSH\n",
    "cmd = f\"nohup python main.py &> {log_file} &\"\n",
    "os.system(cmd)\n",
    "\n",
    "print(\"\\n✓ Training launched in background!\")\n",
    "print(f\"\\nUseful commands:\")\n",
    "print(f\"  Monitor live:     tail -f {log_file}\")\n",
    "print(f\"  Check status:     ps aux | grep 'python main.py'\")\n",
    "print(f\"  Kill if needed:   pkill -f 'python main.py'\")\n",
    "print(f\"  GPU usage:        nvidia-smi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284fec57-66c8-4c11-9e38-7d8b48d50f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor the most recent training log\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# Find most recent log file\n",
    "log_files = sorted(glob.glob('logs/training_*.log'))\n",
    "if log_files:\n",
    "    latest_log = log_files[-1]\n",
    "    print(f\"Monitoring: {latest_log}\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Display last 30 lines\n",
    "    with open(latest_log, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[-30:]:\n",
    "            print(line.rstrip())\n",
    "else:\n",
    "    print(\"No training logs found yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af0fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU utilization\n",
    "import subprocess\n",
    "\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472688be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop training if needed (kills all python main.py processes)\n",
    "import subprocess\n",
    "\n",
    "print(\"Stopping all training processes...\")\n",
    "subprocess.run(['pkill', '-f', 'python main.py'])\n",
    "print(\"✓ Training processes stopped\")\n",
    "\n",
    "# Verify\n",
    "result = subprocess.run(['pgrep', '-f', 'python main.py'], capture_output=True)\n",
    "if result.stdout:\n",
    "    print(\"⚠ Some processes still running, try again or use: kill -9 <PID>\")\n",
    "else:\n",
    "    print(\"✓ All training processes terminated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
