# Deep GCN Model configuration
in_channels: 3
hidden_channels: [16] #32, 64, 128]
out_channels: 2
conv_types: ["GEN"] #,"GEN","GEN", "GEN"]
final_layer_type: "Linear"
activation: "relu"
dropout: 0.1
block: "res" # recommended with heterogeneous dims; residual variants need equal in/out dims
use_bn: true
gat_heads: 4
cheb_K: 3
residual: true 

# Global pooling settings
# Set use_global_pooling=true to enable pooling. Choose where to apply it:
#  - "end": after all layers → graph-level output
#  - "middle": encoder-decoder with pooling bottleneck → node-level output with global context
use_global_pooling: true
pooling_position: middle   # middle | end
pooling_type: attention         # mean | max | sum | attention

# Encoder-decoder split (used when pooling_position: middle)
# If encoder_layers is null, it defaults to half of hidden_layers (here: 4)
encoder_layers: 1

# Optional custom decoder sizes. If null, it mirrors the encoder (reverse of first encoder_layers).
decoder_channels: null

# Optional bottleneck dimension after pooling. If null, uses encoder output dim (here: 512)
graph_output_dim: null

# Encoder-decoder skip connections (only for pooling_position: middle)
# Adds U-Net style skip connections from encoder node features to decoder input
use_ed_skip: true  # Set to true to enable skip connections
ed_skip_type: concat  # "concat" (concatenate) or "add" (elementwise addition)
